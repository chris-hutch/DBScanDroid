from scipy.spatial.distance import pdist, squareform
from sklearn.decomposition import TruncatedSVD

import utils
import csv
import numpy as np
import matplotlib.pyplot as plt
from scipy.sparse import vstack, csr_matrix
from collections import OrderedDict
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.feature_extraction import DictVectorizer


def create_sha256_dict(ground_truth_dest):
    apk_sha256_dict = dict()

    with open(ground_truth_dest, mode='r') as family_sha256_csv:
        reader = csv.DictReader(family_sha256_csv)
        for row in reader:
            apk_sha256_dict[row['sha256']] = row['family']

    return apk_sha256_dict


def construct_feature_vector_matrix(vocab: OrderedDict,
                                    feature_vector_hashes: list,
                                    apk_sha256_map: dict,
                                    feature_vector_parent: str):
    feature_vectors = csr_matrix((1, len(vocab)), dtype=bool)
    # Transform vectorizer over vocab to effectively generate a dictionary
    vectorizer = DictVectorizer(sort=False)
    vectorizer.fit_transform(vocab)

    #### Necessary to create the ground_truth indexes
    n_families = []
    for hashes in feature_vector_hashes:
        n_families.append(apk_sha256_map.get(hashes))
    n_families_without_none = list(filter(None.__ne__, n_families))
    family_mapping = {"Benign": 0}
    family_mapping_n = ({family: v for v, family in enumerate(np.unique(n_families_without_none), 1)})
    family_mapping.update(family_mapping_n)
    y_ground_truth = []
    for idx, apk in enumerate(feature_vector_hashes):
        apk_feature_data = utils.build_feature_vectors(apk, feature_vector_parent)
        # Assign value of 1 in dictionary for feature vectors
        apk_feature_dictionary = {feature: 1 for feature in apk_feature_data}

        # Transform feature dictionary over fitted to produce a binary feature vector
        # 1 means that the feature is there, otherwise a 0
        feature_vector = vectorizer.transform(apk_feature_dictionary)

        feature_vectors = vstack([feature_vectors, feature_vector])
        if apk not in apk_sha256_map:
            y_ground_truth.append(family_mapping["Benign"])
        else:
            y_ground_truth.append(family_mapping[apk_sha256_map[apk]])
    # Delete the first row as it was required to create the csr_matrix
    utils.delete_row_csr(feature_vectors, 0)

    return feature_vectors, y_ground_truth


def compute_jaccard_distance_matrix(feature_vectors: csr_matrix):
    return squareform(pdist(feature_vectors.todense(), metric='jaccard'))

'''
    Run DBSCAN
'''
def run_dbscan_and_plot(eps, min_pts, distance_matrix, y_ground_truth):
    db = DBSCAN(eps=eps, min_samples=min_pts, metric='precomputed').fit(distance_matrix)
    labels = db.labels_
    core_samples = np.zeros_like(labels, dtype=bool)
    core_samples[db.core_sample_indices_] = True
    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
    print('Estimated number of clusters: %d' % n_clusters_)
    unique_labels = set(labels)
    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))
    X_embedded = TruncatedSVD(n_components=2).fit_transform(distance_matrix)
    for k, col in zip(unique_labels, colors):
        if k == -1:
            # Black used for noise.
            col = 'k'
        class_member_mask = (labels == k)
        xy = X_embedded[class_member_mask & ~core_samples]
        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
                 markeredgecolor='k', markersize=6)
        xy = X_embedded[class_member_mask & core_samples]
        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
                 markeredgecolor='k', markersize=8)
    plt.title('Estimated number of clusters: {}. MinPts: {}, Epsilon: {}'.format(n_clusters_, min_pts, eps))
    plt.show()
    print("Adjusted Rand Index: %0.3f"
          % metrics.adjusted_rand_score(y_ground_truth, labels))
    print("Adjusted Mutual Information: %0.3f"
          % metrics.adjusted_mutual_info_score(y_ground_truth, labels))
    print("Purity: %0.3f"
          % utils.purity_score(np.asarray(y_ground_truth), labels))
    print("Silhouette Coefficient: %0.3f"
          % metrics.silhouette_score(distance_matrix, labels))


def print_dataset_stats(feature_vector_hashes, apk_sha256_dict, vocab):
    n_families = []
    for hashes in feature_vector_hashes:
        n_families.append(apk_sha256_dict.get(hashes))
    n_families = [x for x in n_families if x is not None]
    print(np.unique(n_families))
    print("Malware families in ground truth {}".format(len(np.unique(n_families))))
    print("Malicious Apps: {}".format(len(n_families)))
    print("Features: {}".format(len(vocab)))
